.. _rml-intro-label:

======================================================
Introduction to Regularized Maximum Likelihood Imaging
======================================================

This document is an attempt to provide a whirlwind introduction to what Regularized Maximum Likelihood (RML) imaging is, and why you might want to use this MPoL package to perform it with your interferometric dataset. Of course, the field is rich, varied, and this short introduction couldn't possibly do justice to cover the topic in depth. We recommend that you check out many of the links and suggestions in this document for further reading and understanding.

Data in the Fourier domain
--------------------------

MPoL is a package to make images from interferometric data. Currently, we are most focused on modeling datasets from radio interferometers like the `Atacama Large Millimeter Array <https://almascience.nrao.edu/>`__ (ALMA), so the following introduction will have a radio astronomy flavor to it. But the concept of forward modeling interferometric data is quite general, and with a few additions the MPoL package could be applied to imaging problems involving Fourier data from optical and infrared telescopes (if this describes your dataset, please get in touch).

Intereferometers acquire samples of data in the Fourier domain, also called the visibility domain. The visibility domain is the Fourier transform of the image sky brightness

.. math::

    {\cal V}(u,v) = \iint I(l,m) \exp \left \{- 2 \pi i (ul + vm) \right \} \, \mathrm{d}l\,\mathrm{d}m.

Here :math:`l` and :math:`m` are direction cosines (roughly equivalent to R.A. and Dec) which parameterize the surface brightness distribution of the image :math:`I(l,m)`, and :math:`u` and :math:`v` are the spatial frequencies which parameterize the visibility function :math:`\cal{V}(u,v)`. For more information on the meaning of these units, see :ref:`units-conventions-label`.

The visibility function is complex-valued, and each measurement of it (denoted by :math:`V_i`) is made in the presence of noise

.. math::

    V_i = \mathcal{V}(u_i, v_i) + \epsilon.

Here :math:`\epsilon` represents a noise realization from a `complex normal <https://en.wikipedia.org/wiki/Complex_normal_distribution>`__ (Gaussian) distribution. Thankfully, most interferometric datasets do not exhibit significant covariance between the real and imaginary noise components, so we could equivalently say that the real and imaginary components of the noise are separately generated by draws from normal distributions characterized by standard deviation :math:`\sigma`

.. math::

    \epsilon_\Re \sim \mathcal{N}(0, \sigma) \\
    \epsilon_\Im \sim \mathcal{N}(0, \sigma)

and

.. math::

    \epsilon = \epsilon_\Re + i \epsilon_\Im

Radio interferometers will commonly represent the uncertainty on each visibility measurement by a "weight" :math:`w`, where

.. math::

    w = \frac{1}{\sigma^2}

A full interferometric dataset is a collection of visibility measurements, which we represent by

.. math::

    \boldsymbol{V} = \{V_1, V_2, \ldots \}_{i=1}^N

For reference, a typical ALMA dataset might contain a half-million individual visibility samples, acquired over a range of spatial frequencies.


Additional References
+++++++++++++++++++++

A full introduction to Fourier transforms, radio astronomy, and interferometry is beyond the scope of this introduction. However, here are some additional resources that we recommend checking out.

* `Essential radio astronomy <https://www.cv.nrao.edu/~sransom/web/xxx.html>`__ textbook by James Condon and Scott Ransom, and in particular, Chapter 3.7 on Radio Interferometry.
* NRAO's `17th Synthesis Imaging Workshop <http://www.cvent.com/events/virtual-17th-synthesis-imaging-workshop/agenda-0d59eb6cd1474978bce811194b2ff961.aspx>`__ recorded lectures and slides available
* `Interferometry and Synthesis in Radio Astronomy <https://ui.adsabs.harvard.edu/abs/2017isra.book.....T/abstract>`__ by Thompson, Moran, and Swenson. An excellent and comprehensive reference on all things interferometry.


Likelihood functions and parameter inference
--------------------------------------------

Typically, when astronomers fit a model to some dataset, such as a line :math:`y = m x + b` to a collection of :math:`\boldsymbol{X} = \{x_1, x_2, \ldots\, x_N}` and :math:`\boldsymbol{Y} = \{y_1, y_2, \ldots\, y_N}` points, we require a likelihood function. Simply put, the likelihood function specifies the probability of the data, given a model, and encapsulates our assumptions about the data and noise generating processes.

For the line example, let's say each :math:`y_i` data point is generated by

.. math::

    y_i = m x_i + b + \epsilon

where :math:`\epsilon` is a noise realization from a standard normal distribution with standard deviation :math:`\sigma`, i.e.,

.. math::

    \epsilon \sim \mathcal{N}(0, \sigma).

This information about the data and noise generating process means that we can write down a likelihood function to calculate the probability of the data, given a set of model parameters. The likelihood function is :math:`p(\boldsymbol{Y} |\,\boldsymbol{\theta})`. Sometimes it is written as :math:`\mathcal{L}(\boldsymbol{Y} |\,\boldsymbol{\theta})`, and frequently, when employed in computation, we'll use the logarithm of the likelihood function, or "log-likelihood," :math:`\ln \mathcal{L}`. Let's call :math:`\boldsymbol{\theta} = \{m, b\}` and :math:`M(x_i |\, \boldsymbol{\theta}) = m x_i + b`. The likelihood function for this line problem is

.. math::

    \mathcal{L}(\boldsymbol{Y} |\,\boldsymbol{\theta}) = \prod_i^N \frac{1}{\sqrt{2 \pi} \sigma} \exp \left [ - \frac{(y_i - M(x_i |\,\boldsymbol{\theta}))^2}{2 \sigma^2}\right ]

The logarithm of the likelihood function is

.. math::

    \ln \mathcal{L}(\boldsymbol{Y} |\,\boldsymbol{\theta}) = -N \ln(\sqrt{2 \pi} \sigma) - \frac{1}{2} \sum_i^N \frac{(y_i - M(x_i |\,\boldsymbol{\theta}))^2}{\sigma^2}

Assuming that the uncertainty (:math:`\sigma`) on each data point is known and remains constant, the first term is a constant, and we can say that the log likelihood is proportional to

.. math::

    \ln \mathcal{L}(\boldsymbol{Y} |\,\boldsymbol{\theta}) \propto - \frac{1}{2} \sum_i^N \frac{(y_i - M(x_i |\,\boldsymbol{\theta}))^2}{\sigma^2}

You may recognize the right hand term looks similar to :math:`\chi^2` metric,

.. math::

    \chi^2(\boldsymbol{Y} |\,\boldsymbol{\theta}) = \sum_i^N \frac{(y_i - M(x_i |\,\boldsymbol{\theta}))^2}{\sigma^2}

So we say ln = -1/2 chi^2. And shorthand commonly means we have a chi^2 likelihodo funciotn.


And then one way to "fit" a model to data is to find the model parameter values which maximize the likelihood function.

Our statement about the measurement process (:math:`V_i = \mathcal{V}(u_i, v_i) + \epsilon`) defines a likelihood function for complex visibility measurements :math:`\boldsymbol{V}`

.. math::

    \mathcal{L}(\boldsymbol{V} | \boldsymbol{\theta}) =


A side note that this type of parameter inference is entirely `possible with the MPoL package <https://github.com/MPoL-dev/MPoL/issues/33>`__. In fact, the gradient-based nature of things should make this very fast and use advanced sampler like Hamiltonian Monte Carlo.

See the appendix of Loomis et al. 2018 for more information on covariance matrices for spectral fits.

Additional References
+++++++++++++++++++++

For more information about Bayesian inference and likelihood functions, we recommend the following resources.

* Sivia
* Hogg 2012: PRobability Calculus for inference
* Hogg 2010: Fitting a line.

RML images as non-parametric models
-----------------------------------

Examples of splines vs. polynomials.

What is RML imaging?
=
Is

What does that mean?


In general, we are working with Fourier datasets. Meaning that we are trying to reconstruct images of the sky, but the datasets we have are related to the Fourier transform of that.

These types of datasets appear in radio interferometry (such as with ALMA, the JVLA, or very long baseline arrays like the Event Horizon Telescope), or optical interferometry, such as with sparse aperture masking.

Some advantages to doing RML imaging. Provides an alternative to assessing image quality w/ tclean.

Essentially model fitting
Likelihood. Loss functions. (link). Different formulations between Bayesian probability and/or regularizer formulation. An excellent resource here is the EHT-IV paper.

All of this is in contrast to the CLEAN algorithm, which operates as an image-plane deconvolution algorithm.


Additional references for RML imaging
+++++++++++++++++++++++++++++++++++++

* Narayan and Nityananda
* EHT IV

Additional refereces for CLEAN imaging
++++++++++++++++++++++++++++++++++++++

* NRAO summer schools
* CASA documentation



The MPoL package for Regularized Maximum Likelihood imaging
-----------------------------------------------------------

What's new here? Autodifferentiation. Opportunities for expansion. And the tight integration with PyTorch and neural networks. Easy to run on the GPU (link)

2) Getting started with imaging (links to CASA, other imaging software)
3) Getting started with PyTorch


Existing RML packages. Encourage you to check out.

This package is meant to be modular.


### Introduction to Regularized Maximum Likelihood (RML) Imaging

Regularized Maximum Likelihood (RML) imaging is a forward modeling methodology. We predict an image then represent it as an array of pixels. This is brought to the visibility domain through a forward Fourier transform. This is then compared to the measured data to ensure it is a viable predicted image. Due to information loss of the true image when obtaining the measured data, several predicted images- including incorrect ones- will match. To get to our best predicted image, we make new predictions by choosing the most likely (Maximum Likelihood) configuration and favoring specified criteria (Regularized). These criteria or regularizers, are chosen by the user. Some examples of favored criteria are smoothness and sparsity. The likeliness and how well a predicted image meet a certain criterion is mathematically represented in a loss function that contains hyperparameters used to weight data and regularizers. We minimize this loss function by performing a gradient descent, in which we adjust the pixel value intensities. Within this optimization run, hyperparameters are usually held fixed, but can be tuned between runs to produce a better image. When the loss function is minimized, our predicted image is at its best version to fit the collected data and follow our specified criterion.



- Package for synthesis imaging and model fitting from interferometric data.
- Built on PyTorch provides state of the art autodifferentiation capabilities
- Well tested, stable, on supported Python versions. Always a goal of core, usable routines in PyPi releases (i.e., `pip install mpol`). Maintainability.
- Scalability. By keeping modules modular, and *open* and emphasizing the building of imaging components rather than a single, monolithic function, the interested user can expand their applications.

Show the example of HD 143006 CLEAN vs. RML as example of why you might want to use this package… resolution, sensitivity, independent characterization of interesting features.


These could be nice videos, but aspects of them probably need to be tutorials first.

 * Autodifferentiation
     * neural networks, deep learning, graident descent, JAX
 * Layers + Nodes w/in Neural landscape
    * Input and Output connections.
    * Relation of "loss" to Bayesian inference
 * RML Imaging as forward modeling
     * optimization as training

Following on from the layer discussion, and the relationship to Bayesian inference, the idea is that there is some set of parameters that maximize the posterior.


One approach would be to combine all of the data into a single container, and just train/optimize off of that.


But let's say you had a combination of multiple datasets, from different telescope and there was an unknown calibration factor for each telescope.


This approach would be to "batch" the data in the training loop, and train in each step. This training loop is commonly to other neural network architectures.
